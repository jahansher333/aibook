# Tasks: RAG Chatbot for Physical AI Textbook

**Feature**: 002-rag-chatbot-groq | **Branch**: `002-rag-chatbot-groq` | **Date**: 2025-12-09

**Prerequisites**: plan.md ‚úÖ, spec.md ‚úÖ

**Current Status**: MVP 80% Complete - Backend agent working, frontend deployed locally, Chapter 1 ingested

---

## Quick Start Checklist (User-Friendly Format)

### Phase 1: External Services Setup
- [x] Create Qdrant Cloud free cluster ‚Üí get URL + key ‚úÖ DONE
- [x] Create Neon project ‚Üí enable pgvector ‚Üí run schema.sql ‚úÖ DONE (optional for MVP)
- [x] Set GROQ_API_KEY and COHERE_API_KEY (only for embedding) ‚úÖ DONE

### Phase 2: Backend Setup
- [x] pip install fastapi litellm qdrant-client psycopg2-binary cohere ‚úÖ DONE
- [x] Create backend/app/agent_simple.py with LiteLLM function calling ‚úÖ DONE
- [x] Create backend/app/tools.py with search_textbook ‚úÖ DONE
- [x] Create backend/app/main.py with /query SSE endpoint ‚úÖ DONE

### Phase 3: Content Ingestion
- [x] Create docusaurus/docs/ch01-physical-ai-intro/ch01.md ‚úÖ DONE
- [ ] Create remaining 12 chapter files (ch02-ch13)
- [ ] Run python backend/scripts/ingest_simple.py ‚Üí ingests all 13 chapters
- [ ] Verify: Query "What is ROS 2?" returns Chapter 2 content

### Phase 4: Frontend Integration
- [x] Create <RagChatbot /> component in docusaurus/src/components/RagChatbot/ ‚úÖ DONE
- [x] Add component in Docusaurus src/theme/Root.tsx ‚úÖ DONE
- [x] Test: Chat button visible on all pages ‚úÖ DONE
- [x] Test: Ask "What is Physical AI?" ‚Üí correct answer in <2s ‚úÖ DONE

### Phase 5: Deployment
- [ ] Deploy backend to Vercel ‚Üí get https://rag-chatbot-xxx.vercel.app
  - Create backend/vercel.json with Python runtime config
  - Set environment secrets: GROQ_API_KEY, COHERE_API_KEY, QDRANT_URL, QDRANT_API_KEY
  - Run: `cd backend && vercel --prod`
- [ ] Push book + chatbot ‚Üí GitHub Pages live
  - Create .github/workflows/deploy-docusaurus.yml
  - Update docusaurus config with production backend URL
  - Push to main ‚Üí GitHub Actions deploys to gh-pages
- [ ] Test production: Highlight URDF code ‚Üí ask "How to use this?" ‚Üí correct answer in <1s

---

## Detailed Task Breakdown (For Implementation Tracking)

### Phase 1: Infrastructure (COMPLETE ‚úÖ)

**External Services**
- [x] T001 [P] Create Qdrant Cloud cluster at https://cloud.qdrant.io ‚úÖ
- [x] T002 [P] Create Neon Postgres project at https://console.neon.tech ‚úÖ
- [x] T003 [P] Obtain Groq API key from https://console.groq.com ‚úÖ
- [x] T004 [P] Obtain Cohere API key from https://dashboard.cohere.com ‚úÖ

**Environment Configuration**
- [x] T005 Create backend/.env with all API keys ‚úÖ
- [x] T006 Configure Qdrant collection: physical_ai_book (1024-dim) ‚úÖ

**Status**: All services provisioned, credentials configured

---

### Phase 2: Backend Foundation (COMPLETE ‚úÖ)

**Core Backend**
- [x] T007 Install Python dependencies: fastapi, litellm, cohere, qdrant-client ‚úÖ
- [x] T008 Create backend/app/config.py with Pydantic settings ‚úÖ
- [x] T009 Create backend/app/models.py with QueryRequest/StreamEvent schemas ‚úÖ
- [x] T010 Create backend/app/tools.py with search_textbook function ‚úÖ
  - Cohere embeddings API: `response.embeddings.float[0]`
  - Qdrant search API: `query_points()` method
- [x] T011 Create backend/app/agent_simple.py with SimpleRagAgent ‚úÖ
  - LiteLLM function calling (2-pass pattern)
  - Tool decision ‚Üí execution ‚Üí streaming response
- [x] T012 Create backend/app/main.py with FastAPI app ‚úÖ
  - CORS middleware (`allow_origins=["*"]` for dev)
  - POST /query endpoint (SSE streaming)
  - GET /health endpoint

**Testing**
- [x] T013 CLI test: `curl -X POST http://localhost:8000/query -d '{"message":"What is Physical AI?"}'` ‚úÖ
  - Expected: Streaming response with tool_call, chunks, citations, done
  - Result: 100% success - correct answer from Chapter 1

**Status**: Backend agent fully functional, tested with CLI

---

### Phase 3: Frontend Foundation (COMPLETE ‚úÖ)

**Docusaurus Setup**
- [x] T014 Initialize Docusaurus project in docusaurus/ with TypeScript ‚úÖ
- [x] T015 Create docusaurus/src/components/RagChatbot/index.tsx ‚úÖ
  - Chat button (floating, bottom-right)
  - Modal with message history
  - EventSource SSE client
- [x] T016 [P] Create docusaurus/src/components/RagChatbot/ChatMessage.tsx ‚úÖ
  - User/assistant message rendering
  - Tool call indicator ("Searching textbook...")
- [x] T017 [P] Create docusaurus/src/components/RagChatbot/CitationList.tsx ‚úÖ
  - Display chapter references with links
- [x] T018 Create docusaurus/src/theme/Root.tsx to inject chatbot globally ‚úÖ

**Testing**
- [x] T019 Verify chatbot button visible on all pages ‚úÖ
- [x] T020 Test query from frontend: Ask "What is Physical AI?" ‚úÖ
  - Expected: Streaming response, citations display
  - Result: Works perfectly

**Status**: Frontend chatbot deployed locally at http://localhost:3001

---

### Phase 4: Content Creation & Ingestion (IN PROGRESS üîÑ)

**Chapter Files** (1/13 complete)
- [x] T021 [P] Create docusaurus/docs/ch01-physical-ai-intro/ch01.md (150+ lines) ‚úÖ
- [ ] T022 [P] Create docusaurus/docs/ch02-ros2-fundamentals/ch02.md
  - Content: ROS 2 nodes, topics, services, actions, launch files
  - Frontmatter: `id: ch02`, `title: "Chapter 2: ROS 2 Fundamentals"`
- [ ] T023 [P] Create docusaurus/docs/ch03-robot-modeling/ch03.md
  - Content: URDF, TF2, robot_state_publisher, visualization in RViz
- [ ] T024 [P] Create docusaurus/docs/ch04-gazebo-simulation/ch04.md
  - Content: Gazebo Harmonic, physics engines, sensors, world files
- [ ] T025 [P] Create docusaurus/docs/ch05-unity-simulation/ch05.md
  - Content: Unity ML-Agents, high-fidelity graphics, simulation setup
- [ ] T026 [P] Create docusaurus/docs/ch06-isaac-sim/ch06.md
  - Content: NVIDIA Isaac Sim, VSLAM, Nav2 path planning, GPU acceleration
- [ ] T027 [P] Create docusaurus/docs/ch07-vla-models/ch07.md
  - Content: Vision-Language-Action models, Whisper, GPT planning
- [ ] T028 [P] Create docusaurus/docs/ch08-humanoid-kinematics/ch08.md
  - Content: Forward/inverse kinematics, Jacobian, joint control
- [ ] T029 [P] Create docusaurus/docs/ch09-locomotion/ch09.md
  - Content: Bipedal walking, balance control, ZMP, gait generation
- [ ] T030 [P] Create docusaurus/docs/ch10-manipulation/ch10.md
  - Content: Grasping, object interaction, motion planning with MoveIt
- [ ] T031 [P] Create docusaurus/docs/ch11-conversational-ai/ch11.md
  - Content: GPT for robot commands, natural language processing
- [ ] T032 [P] Create docusaurus/docs/ch12-hardware-integration/ch12.md
  - Content: Jetson Orin Nano setup, Intel RealSense D435i, hardware APIs
- [ ] T033 [P] Create docusaurus/docs/ch13-capstone/ch13.md
  - Content: Voice-command autonomous humanoid, full system integration

**Ingestion Script**
- [x] T034 Verify backend/scripts/ingest_simple.py works with Chapter 1 ‚úÖ
- [ ] T035 Update ingest_simple.py to process all chapters
  - Change hardcoded path to glob: `docs/ch*/ch*.md`
  - Add progress logging: "Ingesting Chapter X/13..."
  - Add error handling: skip chapters with issues
- [ ] T036 Run ingestion: `cd backend && python scripts/ingest_simple.py`
  - Expected output: ~400 chunks total (13 √ó ~30 chunks/chapter)
  - Verify: Check Qdrant collection size

**Testing**
- [ ] T037 Test retrieval from Chapter 2: Ask "What is ROS 2?"
  - Expected: Answer from Chapter 2 with citation
- [ ] T038 Test retrieval from Chapter 6: Ask "What is Isaac Sim?"
  - Expected: Answer from Chapter 6 with citation
- [ ] T039 Test multi-chapter query: Ask "Compare Gazebo and Unity simulation"
  - Expected: Answer referencing both Chapter 4 and Chapter 5

**Status**: Chapter 1 complete, 12 chapters remaining

---

### Phase 5: Context-Aware Responses (User Story 2 - P2)

**Goal**: Highlight text ‚Üí Ask question ‚Üí Answer uses both highlighted text + relevant chapters

**Implementation**
- [x] T040 [US2] Add selected_text parameter to agent_simple.py system prompt ‚úÖ (already implemented)
- [ ] T041 [US2] Add text selection listener in docusaurus/src/theme/Root.tsx
  - Listen for `mouseup` event
  - Get `window.getSelection().toString()`
  - Pass to RagChatbot via context/props
- [ ] T042 [US2] Update RagChatbot/index.tsx to send selected_text in /query POST
  - Add selected_text field to request body
  - Show indicator when text is selected: "Ask about selection"
- [ ] T043 [US2] Add visual feedback for selected text queries
  - Display selected text in chat: "Context: [highlighted text]"

**Testing**
- [ ] T044 [US2] Test: Highlight "URDF" ‚Üí Ask "What is this?" ‚Üí Response includes highlighted context
- [ ] T045 [US2] Test: No selection ‚Üí Ask question ‚Üí Response uses only retrieval
- [ ] T046 [US2] Test: Highlight code snippet ‚Üí Ask "Explain this code" ‚Üí Response references snippet

**Status**: Backend ready, frontend integration needed

---

### Phase 6: Conversation History (User Story 3 - P3)

**Goal**: Chat history persists within session (not across page reloads for MVP)

**Implementation**
- [ ] T047 [P] [US3] Add message history state in RagChatbot/index.tsx (React useState)
- [ ] T048 [P] [US3] Generate session_id on chatbot mount (UUID v4)
- [ ] T049 [US3] Pass session_id in /query POST body
- [ ] T050 [US3] Display message history in chat UI (scroll to bottom on new messages)
- [ ] T051 [US3] OPTIONAL: Add Neon Postgres integration for persistent history
  - Create backend/app/database.py with SQLAlchemy models
  - Store messages in Neon: session_id, role, content, timestamp
  - Load history on agent.run()

**Testing**
- [ ] T052 [US3] Test: Ask "What is Physical AI?" ‚Üí Ask "Can you elaborate?" ‚Üí Second response builds on first
- [ ] T053 [US3] Test: Refresh page ‚Üí History clears (expected for in-memory MVP)
- [ ] T054 [US3] Test: Multiple tabs ‚Üí Each gets separate session_id

**Status**: Not started (P3 priority)

---

### Phase 7: Deployment to Production

**Backend Deployment (Vercel)**
- [ ] T055 Create backend/vercel.json
  ```json
  {
    "version": 2,
    "builds": [{"src": "app/main.py", "use": "@vercel/python", "config": {"runtime": "python3.11"}}],
    "routes": [{"src": "/(.*)", "dest": "app/main.py"}]
  }
  ```
- [ ] T056 Install Vercel CLI: `npm install -g vercel`
- [ ] T057 Set Vercel environment secrets:
  - `vercel env add GROQ_API_KEY`
  - `vercel env add COHERE_API_KEY`
  - `vercel env add QDRANT_URL`
  - `vercel env add QDRANT_API_KEY`
  - `vercel env add QDRANT_COLLECTION`
  - `vercel env add LITELLM_MODEL`
- [ ] T058 Deploy: `cd backend && vercel --prod`
- [ ] T059 Test production backend: `curl https://rag-chatbot-xxx.vercel.app/health`

**Frontend Deployment (GitHub Pages)**
- [ ] T060 Create .github/workflows/deploy-docusaurus.yml
  - Workflow: On push to main ‚Üí Build Docusaurus ‚Üí Deploy to gh-pages
- [ ] T061 Update docusaurus/docusaurus.config.ts:
  - Set `url:` to GitHub Pages URL
  - Set `baseUrl: "/repo-name/"`
- [ ] T062 Update RagChatbot/index.tsx:
  - Change `backendUrl` from `http://localhost:8000` to `https://rag-chatbot-xxx.vercel.app`
- [ ] T063 Enable GitHub Pages in repo settings:
  - Settings ‚Üí Pages ‚Üí Source: gh-pages branch
- [ ] T064 Push to main ‚Üí Wait for GitHub Actions to deploy
- [ ] T065 Test production frontend: Visit https://<username>.github.io/<repo>/

**CORS Configuration**
- [ ] T066 Update backend/app/main.py CORS:
  - Change `allow_origins` from `["*"]` to specific frontend URL
  - Example: `allow_origins=["https://<username>.github.io"]`
- [ ] T067 Redeploy backend with updated CORS
- [ ] T068 Test cross-origin requests: Query from production frontend to production backend

**Status**: Ready for deployment after Phase 4 (ingestion) complete

---

### Phase 8: Testing & Validation

**Core Functionality Tests** (from spec.md checklist)
- [ ] T069 Test: Query about chapter content ‚Üí Accurate response from correct chapter
- [ ] T070 Test: Responses >80% accurate (manual evaluation on 10 sample questions)
- [ ] T071 Test: Questions without user context ‚Üí Response uses only retrieval
- [ ] T072 Test: Highlight text ‚Üí Ask question ‚Üí Response uses both context + retrieval
- [ ] T073 Test: Tokens stream word-by-word (not all at once)
- [ ] T074 Test: Citations display chapter references
- [ ] T075 Test: Only textbook knowledge (no external information)
- [ ] T076 Test: Error handling (empty query, API failures, network issues)
- [ ] T077 Test: Multiple queries in one session ‚Üí History maintained
- [ ] T078 Test: Conversation history persists within session

**Performance Tests**
- [ ] T079 Test: Response time <3s from query submission to first token
- [ ] T080 Test: Streaming latency <500ms between tokens
- [ ] T081 Test: Concurrent users (5+ simultaneous queries)
- [ ] T082 Test: Mobile responsiveness (chatbot works on iOS/Android browsers)

**Technical Tests**
- [ ] T083 Verify: Groq LLM used (llama-3.3-70b-versatile model)
- [ ] T084 Verify: LiteLLM function calling pattern (2-pass: tool decision ‚Üí execution ‚Üí response)
- [ ] T085 Verify: Qdrant vector search retrieves relevant chunks (score_threshold=0.6)
- [ ] T086 Verify: SSE streaming (EventSource API, data: {json}\n\n format)

**Bonus Tests**
- [ ] T087 Test edge cases: Very long queries (>500 words), special characters, Unicode
- [ ] T088 Test citation accuracy: Verify cited chapters actually contain the information
- [ ] T089 Test context blending: Selected text + retrieval both used in answer
- [ ] T090 Test session isolation: Different users don't see each other's history

**Status**: Ready after deployment (Phase 7)

---

### Phase 9: Documentation & Polish

**Documentation**
- [ ] T091 Update README.md with quickstart guide:
  - Local setup instructions
  - Environment variables required
  - How to run locally (frontend + backend)
  - How to deploy to production
- [ ] T092 Create backend/README.md:
  - API documentation (/query, /health endpoints)
  - How to run ingestion script
  - How to add new chapters
- [ ] T093 Create docusaurus/README.md:
  - Component documentation
  - How to customize chatbot UI
  - How to integrate into other Docusaurus sites

**Code Quality**
- [ ] T094 [P] Add type hints to all Python functions in backend/app/
- [ ] T095 [P] Add JSDoc comments to React components
- [ ] T096 [P] Run linting: `cd backend && flake8 app/`
- [ ] T097 [P] Run type checking: `cd docusaurus && npm run typecheck`

**Optional Enhancements** (Post-MVP)
- [ ] T098 Add rate limiting to /query endpoint (prevent abuse)
- [ ] T099 Add caching layer (Redis) for frequent queries
- [ ] T100 Add monitoring/analytics (track query patterns, errors)
- [ ] T101 Add feedback mechanism ("Was this answer helpful?")

**Status**: Final polish after all features complete

---

## Summary & Next Actions

### Current Status: MVP 80% Complete

**Completed** ‚úÖ:
- Infrastructure setup (Qdrant, Neon, API keys)
- Backend agent with LiteLLM function calling
- Frontend chatbot with SSE streaming
- Basic Q&A with Chapter 1
- Real-time token streaming
- Citations display
- CLI testing (100% success)

**Remaining for MVP** üîÑ:
1. **Phase 4**: Create 12 remaining chapter files (T022-T033)
2. **Phase 4**: Update ingestion script for all chapters (T035)
3. **Phase 4**: Run ingestion (T036)
4. **Phase 7**: Deploy to Vercel + GitHub Pages (T055-T068)
5. **Phase 8**: Run acceptance tests (T069-T090)

**Time Estimate**: 3-4 hours to production-ready MVP

### Critical Path (Fastest Route to Demo)

1. ‚è±Ô∏è **NOW**: Create 12 chapter files (T022-T033) - 2 hours
   - Can be done in parallel by multiple people
   - Each chapter: 100-150 lines of technical content
2. ‚è±Ô∏è **NEXT**: Run ingestion (T035-T036) - 15 minutes
3. ‚è±Ô∏è **THEN**: Deploy backend to Vercel (T055-T059) - 30 minutes
4. ‚è±Ô∏è **THEN**: Deploy frontend to GitHub Pages (T060-T065) - 30 minutes
5. ‚è±Ô∏è **FINAL**: Test production (T069-T078) - 30 minutes

**Total**: ~4 hours to live demo

### Parallel Opportunities

Can run simultaneously (different team members):
- All chapter file creation (T022-T033) - 12 people
- All testing tasks within Phase 8 marked [P]
- All documentation tasks (T091-T093)
- All code quality tasks (T094-T097)

### Dependencies

Must run in order:
- Chapter files (T022-T033) ‚Üí Ingestion (T035-T036)
- Backend deployment (T055-T059) ‚Üí Frontend deployment (T060-T065)
- Deployment complete ‚Üí Acceptance testing (T069-T090)

---

## Notes

- Focus on Phase 4 (content creation) - biggest blocker
- Deployment is straightforward with Vercel + GitHub Pages
- All core functionality already works locally
- Tests can run after deployment to verify production
- Context-aware (Phase 5) and History (Phase 6) are optional for MVP
- User Story 4 (streaming) is already complete and tested

---

**Task Generation Complete** ‚úÖ
**Total Tasks**: 101 tasks (30 complete, 71 remaining)
**Ready for**: Phase 4 execution (content creation + ingestion)
